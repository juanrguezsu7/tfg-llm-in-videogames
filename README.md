# Usage of Large Language Models in Videogames
## Objective
The main purpose of this project is to leverage the potential of the recent LLM in videogames. Specifically, enhancing dialogues, some game mechanics and improving accessibility.
## Main tools
- Unity to develop the entire game.
- [LlamaCpp](https://github.com/ggml-org/llama.cpp) to deploy a local server to serve all HTTP requests regarding the local models and quantize them.
- [HuggingFace](https://huggingface.co) to download many open-source models and test them.
## Installation
- Download and unzip the .zip file in releases and execute the .exe.
## Features
- All dialogues are driven by OpenAI GPT-4o-mini following strict instructions about how to imitate the different characters of the story.
- All NPC are able to generate automatic quests to the player if requested. These quests give also an automatic reward. Both quests and rewards are automatically generated by the AI depending on many factors like the relation with the player, the personality, etc.
- Voice Commands can be given using the ยบ key. These commands are interpreted by the same previous model and traslated into text by Whisper. For now, two commands are available: a killing command which will shoot the nearest enemy and a move-to which will automatically move to a specific character.
- Contextual translation of dialogues into Spanish or English. These translations can be performed using the Up and Down arrows in order to translate the user's input or the NPC's output. These translations are done using Opus-MT models.
